{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#introduction","title":"Introduction","text":"<p>GLIM is a versatile and extensible range-based 3D mapping framework.</p> <ul> <li>Accuracy: GLIM is based on direct multi-scan registration error minimization on factor graphs that enables to accurately retain the consistency of mappint results. GPU acceleration is supported to maximize the mapping speed and quality.</li> <li>Easy-to-use: GLIM offers an interactive map correction interface that enables the user to manually correct mapping failures and easily refine mapping results.</li> <li>Versatility: As we eliminated sensor-specific processes, GLIM can be applied to any kind of range sensors including:<ul> <li>Spinning-type LiDAR (e.g., Velodyne HDL32e)</li> <li>Non-repetitive scan LiDAR (e.g., Livox Avia)</li> <li>Solid-state LiDAR (e.g., Intel Realsense L515)</li> <li>RGB-D camera (e.g., Microsoft Azure Kinect)</li> </ul> </li> <li>Extensibility: GLIM provides the global callback slot mechanism that allows to access the internal states of the mapping process and insert additional constraints to the factor graph. We also release glim_ext that offers example implementations of several extension functions (e.g., explicit loop detection, LiDAR-Visual-Inertial odometry estimation).</li> </ul> <p>Tested on Ubuntu 22.04 / 24.04 with CUDA 12.2 / 12.5, and NVIDIA Jetson Orin (Jetpack 6.0).</p> <p> </p>"},{"location":"index.html#video","title":"Video","text":""},{"location":"index.html#robustness-test","title":"Robustness test","text":""},{"location":"index.html#mapping-with-various-range-sensors","title":"Mapping with various range sensors","text":""},{"location":"index.html#outdoor-driving-test-with-livox-mid360","title":"Outdoor driving test with Livox MID360","text":"<p>See more in Extension modules and Demo pages.</p>"},{"location":"index.html#contact","title":"Contact","text":"<p>Kenji Koide   National Institute of Advanced Industrial Science and Technology (AIST), Japan</p>"},{"location":"api.html","title":"API list","text":""},{"location":"api.html#doxygen-generated-api-list","title":"Doxygen generated API list","text":"<ul> <li>gtsam_points: GTSAM factors for range-based SLAM</li> <li>glim: LiDAR-IMU localization and mapping</li> </ul>"},{"location":"api.html#related-repositories","title":"Related Repositories","text":"<ul> <li>gtsam_points (https://github.com/koide3/gtsam_points)</li> <li>glim (https://github.com/koide3/glim)</li> <li>glim_ros1 (https://github.com/koide3/glim_ros1)</li> <li>glim_ros2 (https://github.com/koide3/glim_ros2)</li> <li>glim_ext (https://github.com/koide3/glim_ext)</li> </ul>"},{"location":"demo.html","title":"Demo data","text":"<p>See more videos at Video Gallery.</p>"},{"location":"demo.html#mapping-with-various-range-sensors","title":"Mapping with various range sensors","text":"<ul> <li>Download dataset</li> <li>config_versatile.tar.gz</li> </ul> <pre><code>ros2 run glim_ros glim_rosbag --ros-args -p config_path:=$(realpath config/kinect) kinect\n</code></pre> <p>Tip</p> <p>The same parameter set was used for all the sensors.</p> <p>Warning</p> <p>As can be seen in the video, the quality of point clouds of stereo-based sensors (D455 and ZED2i) is not very good, and GLIM, which is based on point cloud matching, does not always work well with these sensors. We recommend using other vision-based SLAM packages for stereo sensors.</p>"},{"location":"demo.html#flat-wall-experiment","title":"Flat wall experiment","text":"<ul> <li>Download dataset </li> <li>config_flatwall.tar.gz</li> </ul>"},{"location":"demo.html#outdoor-driving-test-with-livox-mid360","title":"Outdoor driving test with Livox MID360","text":""},{"location":"demo.html#indoor-mapping-with-azure-kinect","title":"Indoor mapping with Azure Kinect","text":""},{"location":"demo.html#real-time-mapping-on-jetson-nano","title":"Real-time mapping on Jetson Nano","text":"<ul> <li>os1_128_01_downsampled.bag (515MB)</li> <li>config_nano_cpu.zip</li> <li>config_nano_gpu.zip</li> </ul> <p>Note</p> <ul> <li>Only odometry estimation was performed, no global optimization.</li> <li>Visualization was run on another PC that received points and pose messages via ethernet.   (rviz took about a half of Jetson Nano's computation capability without rendering anything!!)</li> <li>(2024/07/04) The current version of GLIM does not support CUDA 11 and older. Some minor midifications are expected to be necessary.</li> </ul>"},{"location":"docker.html","title":"Docker images","text":""},{"location":"docker.html#prebuilt-docker-images","title":"Prebuilt docker images","text":"<p>We provide the following docker images for ROS1 and ROS2 environments on docker hub.</p> <ul> <li> koide3/glim_ros1:noetic</li> <li> koide3/glim_ros1:noetic_cuda12.2</li> <li> koide3/glim_ros2:jazzy</li> <li> koide3/glim_ros2:humble</li> <li> koide3/glim_ros2:humble_cuda12.2</li> </ul> <p>Note</p> <p>ROS2 sometimes requires additional configurations for communication on docker. See https://github.com/eProsima/Fast-DDS/issues/2956. Do not ask us about how to use ROS2 with docker.</p> <p>Note</p> <p>Currently, we provide only AMD64 images. ARM64 support is planned in the future.</p>"},{"location":"docker.html#example-use","title":"Example use","text":""},{"location":"docker.html#with-gpu","title":"With GPU","text":"<pre><code># Copy config and edit as you want\ngit clone git@github.com:koide3/glim /tmp/glim\ncp -R /tmp/glim/config ./config\n\n# Pull image from docker hub\ndocker pull koide3/glim_ros2:humble_cuda12.2\n\n# Launch glim_ros2:humble_cuda12.2 image with GPU and DISPLAY support\ndocker run \\\n  -it \\\n  --rm \\\n  --net=host \\\n  --ipc=host \\\n  --pid=host \\\n  --gpus all \\\n  -e=DISPLAY \\\n  -e=ROS_DOMAIN_ID \\\n  -v $(realpath config):/glim/config \\\n  koide3/glim_ros2:humble_cuda12.2 \\\n  ros2 run glim_ros glim_rosnode --ros-args -p config_path:=/glim/config\n</code></pre>"},{"location":"docker.html#without-gpu","title":"Without GPU","text":"<pre><code># Copy config and edit it\ngit clone git@github.com:koide3/glim /tmp/glim\ncp -R /tmp/glim/config ./config\n\n# Change as follows:\n# \"config_odometry\" : \"config_odometry_cpu.json\"\n# \"config_sub_mapping\" : \"config_sub_mapping_cpu.json\"\n# \"config_global_mapping\" : \"config_global_mapping_cpu.json\"\nnano config/config.json\n\n# Pull image from docker hub\ndocker pull koide3/glim_ros2:humble\n\n# Launch glim_ros2:humble image with DISPLAY support\ndocker run \\\n  -it \\\n  --rm \\\n  --net=host \\\n  --ipc=host \\\n  --pid=host \\\n  --gpus all \\\n  -e=DISPLAY \\\n  -e=ROS_DOMAIN_ID \\\n  -v $(realpath config):/glim/config \\\n  koide3/glim_ros2:humble \\\n  ros2 run glim_ros glim_rosnode --ros-args -p config_path:=/glim/config\n</code></pre>"},{"location":"docker.html#build-docker-images-from-source","title":"Build docker images from source","text":"<pre><code>mkdir /tmp/glim_docker &amp;&amp; cd /tmp/glim_docker\ngit clone git@github.com:koide3/glim\ngit clone git@github.com:koide3/glim_ros2\n\n# Without GPU\ndocker build \\\n  -f glim_ros2/docker/Dockerfile.gcc \\\n  --build-arg=\"BASE_IMAGE=koide3/gtsam_points:jammy\" \\\n  --build-arg=\"ROS_DISTRO=humble\" \\\n  --tag glim_ros2:humble \\\n  .\n\n# With GPU\ndocker build \\\n  -f glim_ros2/docker/Dockerfile.gcc.cuda \\\n  --build-arg=\"BASE_IMAGE=koide3/gtsam_points:jammy_cuda12.2\" \\\n  --build-arg=\"ROS_DISTRO=humble\" \\\n  --tag glim_ros2:humble_cuda12.2 \\\n  .\n</code></pre>"},{"location":"extend.html","title":"Extending GLIM","text":""},{"location":"extend.html#notation","title":"Notation","text":"<p>In this package, the (SE3) transformation from frame B to frame A is denoted as <code>T_A_B</code>. In other words, a point <code>p_B</code> in the frame B is transformed into the frame A by <code>T_A_B</code> (i.e., <code>p_A = T_A_B * p_B</code>).</p> <p>For instance, the transformation from a LiDAR frame to the world frame (i.e., a LiDAR pose in the world frame) is represented as <code>T_world_lidar</code>, and a point in the LiDAR frame <code>p_lidar</code> is transformed into the world frame by <code>p_world = T_world_lidar * p_lidar</code>.</p> <p>Similarty, <code>v_A_B</code> represents the velocity of frame B in frame A, and thus <code>v_world_imu</code> represents an IMU velocity in the world frame.</p>"},{"location":"extend.html#variables","title":"Variables","text":""},{"location":"extend.html#variable-addressing-in-gtsam","title":"Variable addressing in GTSAM","text":"<p>In GTSAM, variables can be addressed using the gtsam::Symbol class that combines a symbol label (a character, e.g., 'x') and a variable index. For example, you can insert a pose variable into gtsam::Values and label it as <code>X(i)</code> as follows:</p> <pre><code>using gtsam::symbol_shorthand::X;\n\nint id = 0;\ngtsam::Pose3 pose;\n\ngtsam::Values values;\nvalues.insert(X(id), pose);\n</code></pre> <p>Info</p> <p>See 5.2. Keys and Symbols in this tutorial for more details.</p>"},{"location":"extend.html#variables-in-glim","title":"Variables in GLIM","text":"<p>In the following, we show the graph structures and variables in the odometry estimation and global optimization algorithms of GLIM. Through the global callback slot mechanism, which will be explained later, you can access variables in the factor graphs and create additional constraints (i.e., factors) to improve the accuracy/stability/robustness of the mapping process in specific situations.</p>"},{"location":"extend.html#variables-in-the-odometry-estimation","title":"Variables in the odometry estimation","text":"<ul> <li><code>X(i)</code> : IMU pose = T_odom_imu (gtsam::Pose3)</li> <li><code>V(i)</code> : IMU velocity = v_odom_imu (gtsam::Vector3)</li> <li><code>B(i)</code> : IMU bias (gtsam::imuBias::ConstantBias)</li> </ul> <p>Note</p> <p>In the odometry estimation, old variables are eliminated from the graph when they leave the sliding optimization window specified by the smoother_lag param (e.g., 5 sec). You thus need to ensure that additional factors refer to only variables in this optimization window. </p> <p>Note</p> <p>Because odometry_ct performs LiDAR-only estimation, it does not create <code>V(i)</code> and <code>B(i)</code>, and <code>X(i)</code> represents the LiDAR pose instead of the IMU pose.</p> <p>Info</p> <p>\"velocity_suppressor.cpp\" in gtsam_points shows a simple example to insert velocity suppression factors into the odometry estimation factor graph.</p>"},{"location":"extend.html#variables-in-the-global-optimization","title":"Variables in the global optimization","text":"<p>Sub mapping states:</p> <ul> <li><code>X(i)</code> : Sensor pose = T_odom_sensor (gtsam::Pose3)</li> <li><code>V(i)</code> : IMU velocity = v_odom_sensor (gtsam::Vector3)</li> <li><code>B(i)</code> : IMU bias (gtsam::imuBias::ConstantBias)</li> </ul> <p>Global mapping states:</p> <ul> <li><code>X(i)</code> : Submap pose = T_world_submap (gtsam::Pose3)</li> <li><code>V(2 * i) &amp; V(2 * i + 1)</code> : IMU velocity at endpoints (gtsam::Vector3)</li> <li><code>B(2 * i) &amp; V(2 * i + 1)</code> : IMU bias at endpoints (gtsam::Vector3)</li> </ul>"},{"location":"extend.html#global-callback-slot","title":"Global callback slot","text":"<p>The global callback slot is a mechanism to hook processing steps in the mapping system. It enables to access the internal states of the mapping process and insert additional factors into the factor graph. The following code demonstrates how we can register a callback function to the new frame creation event in the odometry estimation and retrieve estimated sensor states of the latest frame.</p> <pre><code>#include &lt;glim/odometry/callback.hpp&gt;\n\nusing namespace glim;\n\nvoid on_new_frame(const EstimationFrame::ConstPtr&amp; new_frame) {\n  const long id = new_frame-&gt;id;                                    // Frame ID\n  const double stamp = new_frame-&gt;stamp;                            // Timestamp\n  const Eigen::Isometry3d&amp; T_world_imu = new_frame-&gt;T_world_imu;    // IMU pose\n}\n\nvoid setup_callback() {\n  using std::placeholders::_1;\n  OdometryEstimationCallback::on_new_frame.add(std::bind(&amp;on_new_frame, _1));\n}\n</code></pre> <p>Take a look at the following links to see what can be retrieved from and inserted into the system via global callback slots:</p> <ul> <li>OdometryEstimationCallbacks</li> <li>SubMappingCallbacks</li> <li>GlobalMappingCallbacks</li> </ul> <p>Warning</p> <p>Each of odometry estimation, submapping, and global mapping modules are run in different threads, and thus their callbacks can be called from different threads. You must take care of the thread-safety of your extension module if it subscribes to events from different modules.</p>"},{"location":"extend.html#extension-module","title":"Extension module","text":"<p>GLIM offers a mechanism to load extension modules from shared libraries at run-time. To implement an extension module, you need to write your extension module class that inherits from glim::ExtensionModule and define a loading function named create_extension_module() that returns an instance of your extension class.</p> my_extension_module.cpp<pre><code>#include &lt;glim/odometry/callbacks.hpp&gt;\n#include &lt;glim/util/extension_module.hpp&gt;\n\nusing namespace glim;\n\nclass MyExtensionModule : public ExtensionModule {\npublic:\n  MyExtensionModule() {\n    using std::placeholders::_1;\n    OdometryEstimationCallbacks::on_new_frame.add(std::bind(&amp;MyExtensionModule::on_new_frame, this, _1));\n  }\n\n  void on_new_frame(const EstimationFrame::ConstPtr&amp; frame) {\n    // ...\n  }\n};\n\nextern \"C\" ExtensionModule* create_extension_module() {\n  return new MyExtensionModule();\n}\n</code></pre> CMakeLists.txt<pre><code>cmake_minimum_required(VERSION 3.5.2)\nproject(my_extension_module)\n\nset(CMAKE_CXX_STANDARD 17)\n\nfind_package(glim REQUIRED)\n\nadd_library(my_extension_module SHARED\n  src/my_extension_module.cpp\n)\ntarget_link_libraries(my_extension_module\n  glim::glim\n)\n</code></pre> <p>The extension module can be loaded into GLIM by adding the name of the created shared library to <code>extension_modules</code> parameter in <code>glim/config/config_ros.json</code>.</p> <p>Note</p> <p>If you don't want to use the dynamic loading mechanism, it is also possible to create an extension by directly modifying <code>glim_ros.cpp</code>, of course.</p>"},{"location":"extensions.html","title":"Extension modules","text":""},{"location":"extensions.html#open-source-extension-modules","title":"Open-source extension modules","text":"<p>glim_ext provides example implementations of extension modules that demonstrate the extensibility of GLIM. All the implemented modules are decoupled from GLIM main components and inter-module communication is conducted via the global callback slot mechanism.</p> <p>Warning</p> <p>The implementations in glim_ext are proof-of-concept code for showing the extensibility of GLIM. They may not be well-maintained and may not be suitable for practical purposes.</p> <p>Warning</p> <p>Each module in glim_ext uses several external libraries that employ different licenses. You must carefully check and follow their licensing conditions.</p>"},{"location":"extensions.html#installation","title":"Installation","text":"<pre><code>cd ~/ros2_ws/src\ngit clone https://github.com/koide3/glim_ext\n\ncd ~/ros2_ws\ncolcon build\n</code></pre>"},{"location":"extensions.html#odometry-estimation-modules","title":"Odometry estimation modules","text":""},{"location":"extensions.html#orb_slam-based-loose-visual-integration","title":"ORB_SLAM-based loose visual integration","text":"<ul> <li>Loosely coupled visual odometry estimation constraints based on ORB_SLAM3</li> <li>Dependency: ORB_SLAM3 (GPL-3.0)</li> </ul>"},{"location":"extensions.html#velocity-suppressor","title":"Velocity suppressor","text":"<ul> <li>Constraints to regulate IMU velocity</li> </ul>"},{"location":"extensions.html#imu-calibration-validator","title":"IMU calibration validator","text":"<ul> <li>Utility module to validate the LiDAR-IMU transformation (See FAQ)</li> </ul>"},{"location":"extensions.html#global-optimization-modules","title":"Global optimization modules","text":""},{"location":"extensions.html#gnss-constraints-ros2-only","title":"GNSS constraints [ROS2 only]","text":"<ul> <li>Naive implementation of GNSS global optimization constraints</li> </ul>"},{"location":"extensions.html#scancontext-loop-detector","title":"ScanContext loop detector","text":"<ul> <li>Explicit loop detection based on ScanContext</li> <li>Dependency: ScanContext (CC BY-NC-SA 4.0)</li> </ul>"},{"location":"extensions.html#dbow-loop-detector","title":"DBoW loop detector","text":"<ul> <li>Explicit loop detection based on DBoW3</li> <li>Dependency: DBoW3 (LICENSE)</li> </ul>"},{"location":"extensions.html#closed-source-extension-modules","title":"Closed-source extension modules","text":"<p>The following modules are provided as closed-source packages. Contact us if you are interested in the closed-source modules.</p>"},{"location":"extensions.html#tightly-coupled-multi-lidar-odometry-estimation-module","title":"Tightly-coupled multi-LiDAR odometry estimation module","text":""},{"location":"extensions.html#tightly-coupled-multi-camera-odometry-estimation-module","title":"Tightly-coupled multi-camera odometry estimation module","text":""},{"location":"extensions.html#dense-mapping-and-colorization-module","title":"Dense mapping and colorization module","text":""},{"location":"faq.html","title":"FAQ","text":"<p>Moved to wiki/FAQ.</p>"},{"location":"installation.html","title":"Installation","text":"<p>GLIM is tested on Ubuntu 22.04 / 24.04 with CUDA 12.2 / 12.5, and NVIDIA Jetson Orin (JetPack 6.0). You can build and install GLIM from source code, or install pre-built binaries from PPA.</p>"},{"location":"installation.html#install-from-source","title":"Install from source","text":""},{"location":"installation.html#common-dependencies","title":"Common dependencies","text":"<pre><code># Install dependencies\nsudo apt install libomp-dev libboost-all-dev libmetis-dev \\\n                 libfmt-dev libspdlog-dev \\\n                 libglm-dev libglfw3-dev libpng-dev libjpeg-dev\n\n# Install GTSAM\ngit clone https://github.com/borglab/gtsam\ncd gtsam &amp;&amp; git checkout 4.2a9\nmkdir build &amp;&amp; cd build\ncmake .. -DGTSAM_BUILD_EXAMPLES_ALWAYS=OFF \\\n         -DGTSAM_BUILD_TESTS=OFF \\\n         -DGTSAM_WITH_TBB=OFF \\\n         -DGTSAM_USE_SYSTEM_EIGEN=ON \\\n         -DGTSAM_BUILD_WITH_MARCH_NATIVE=OFF\nmake -j$(nproc)\nsudo make install\n\n# Install Iridescence for visualization\n# This is optional but highly recommended\ngit clone https://github.com/koide3/iridescence --recursive\nmkdir iridescence/build &amp;&amp; cd iridescence/build\ncmake .. -DCMAKE_BUILD_TYPE=Release\nmake -j$(nproc)\nsudo make install\n\n\n# Install gtsam_points\ngit clone https://github.com/koide3/gtsam_points\nmkdir gtsam_points/build &amp;&amp; cd gtsam_points/build\ncmake .. -DBUILD_WITH_CUDA=ON\nmake -j$(nproc)\nsudo make install\n\n\n# Make shared libraries visible to the system\nsudo ldconfig\n</code></pre>"},{"location":"installation.html#install-glim-for-ros1","title":"Install GLIM for ROS1","text":"<pre><code>cd ~/catkin_ws/src\ngit clone https://github.com/koide3/glim\ngit clone https://github.com/koide3/glim_ros1\n\ncd ~/catkin_ws\ncatkin_make\n\n# cmake options\n# catkin_make \\\n#   -DBUILD_WITH_CUDA=ON \\\n#   -DBUILD_WITH_VIEWER=ON \\\n#   -DBUILD_WITH_MARCH_NATIVE=OFF\n</code></pre>"},{"location":"installation.html#install-glim-for-ros2","title":"Install GLIM for ROS2","text":"<pre><code>cd ~/ros2_ws/src\ngit clone https://github.com/koide3/glim\ngit clone https://github.com/koide3/glim_ros2\n\ncd ~/ros2_ws\ncolcon build\n\n# cmake options\n# colcon build --cmake-args \\\n#   -DBUILD_WITH_CUDA=ON \\\n#   -DBUILD_WITH_VIEWER=ON \\\n#   -DBUILD_WITH_MARCH_NATIVE=OFF\n</code></pre> <p>Note</p> <p>While AVX intrinsics can be enabled to speed up the mapping process by setting <code>BUILD_WITH_MARCH_NATIVE=ON</code>, it sometimes causes segfaults unless <code>march=native</code> is properly set for every involved library. We recommend keeping it disabled if you are not sure.</p>"},{"location":"installation.html#install-from-ppa-ubuntu-2404-2204-2004-amd64-arm64","title":"Install from PPA [Ubuntu 24.04 , 22.04, 20.04 / AMD64, ARM64]","text":""},{"location":"installation.html#prerequisite","title":"Prerequisite","text":"<pre><code>sudo apt install curl gpg\n</code></pre>"},{"location":"installation.html#setup-ppa","title":"Setup PPA","text":"<pre><code># Choose one of the follows\n\n# Automatically setup PPA via online script\ncurl -s https://koide3.github.io/ppa/setup_ppa.sh | sudo bash\n\n# Manually setup PPA for Ubuntu 24.04\ncurl -s --compressed \"https://koide3.github.io/ppa/ubuntu2404/KEY.gpg\" | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/koide3_ppa.gpg &gt;/dev/null\necho \"deb [signed-by=/etc/apt/trusted.gpg.d/koide3_ppa.gpg] https://koide3.github.io/ppa/ubuntu2404 ./\" | sudo tee /etc/apt/sources.list.d/koide3_ppa.list\n\n# Manually setup PPA for Ubuntu 22.04\ncurl -s --compressed \"https://koide3.github.io/ppa/ubuntu2204/KEY.gpg\" | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/koide3_ppa.gpg &gt;/dev/null\necho \"deb [signed-by=/etc/apt/trusted.gpg.d/koide3_ppa.gpg] https://koide3.github.io/ppa/ubuntu2204 ./\" | sudo tee /etc/apt/sources.list.d/koide3_ppa.list\n\n# Manually setup PPA for Ubuntu 20.04\ncurl -s --compressed \"https://koide3.github.io/ppa/ubuntu2004/KEY.gpg\" | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/koide3_ppa.gpg &gt;/dev/null\necho \"deb [signed-by=/etc/apt/trusted.gpg.d/koide3_ppa.gpg] https://koide3.github.io/ppa/ubuntu2004 ./\" | sudo tee /etc/apt/sources.list.d/koide3_ppa.list\n</code></pre>"},{"location":"installation.html#install-dependencies","title":"Install dependencies","text":"<pre><code>sudo apt update\nsudo apt install -y libiridescence-dev libboost-all-dev libglfw3-dev libmetis-dev\n\n# Choose one of the follows\nsudo apt install -y libgtsam-points-dev           # without CUDA\nsudo apt install -y libgtsam-points-cuda12.2-dev  # with CUDA 12.2\nsudo apt install -y libgtsam-points-cuda12.5-dev  # with CUDA 12.5\n</code></pre>"},{"location":"installation.html#install-glim-for-ros","title":"Install GLIM for ROS","text":"<pre><code># Choose one of the follows\n\n# ROS2 jazzy (Ubuntu 24.04)\nsudo apt install -y ros-jazzy-glim-ros             # Without CUDA\nsudo apt install -y ros-jazzy-glim-ros-cuda12.5    # With CUDA 12.5\n\n# ROS2 humble (Ubuntu 22.04)\nsudo apt install -y ros-humble-glim-ros            # Without CUDA\nsudo apt install -y ros-humble-glim-ros-cuda12.2   # With CUDA 12.2\nsudo apt install -y ros-humble-glim-ros-cuda12.5   # With CUDA 12.5\n\n# ROS1 noetic (Ubuntu 20.04)\nsudo apt install -y ros-noetic-glim-ros            # Without CUDA\nsudo apt install -y ros-noetic-glim-ros-cuda12.2   # With CUDA 12.2\nsudo apt install -y ros-noetic-glim-ros-cuda12.5   # With CUDA 12.5\n</code></pre>"},{"location":"parameters.html","title":"Important parameters","text":"<p>Info</p> <p>See the sensor setup buide for configurations of popular sensors (including Livox MID360 and Azure Kinect).</p> <p>Info</p> <p>See the Configuration files section in Getting started to change the location of configuration files.</p>"},{"location":"parameters.html#ros-related-config_rosjson","title":"ROS-related (config_ros.json)","text":"<ul> <li>acc_scale (default 1.0) : Linear acceleration scaling factor. Set this to 9.80665 if the unit of IMU linear acceleration is [g] but not [m/s^2] (e.g., Livox LiDARs). </li> <li>(imu|points|image)_topics : Input data topics.</li> </ul>"},{"location":"parameters.html#sensor-configuration-config_sensorsjson","title":"Sensor configuration (config_sensors.json)","text":"<ul> <li>T_lidar_imu : Transformation from the IMU frame to the LiDAR frame (See notation). When the IMU is at rest and the IMU z-axis points upwards, linear acceleration vector should be around [0, 0, +9.81] (See also ROS REP 145 and FAQ).</li> </ul>"},{"location":"parameters.html#preprocessing-config_preprocessjson","title":"Preprocessing (config_preprocess.json)","text":"<ul> <li> <p>random_downsample_target (default 10000 points): Target number of points for downsampling. Reducing the target number of points (e.g., to 5000) makes estimation significantly faster.</p> </li> <li> <p>k_correspondences (default 10 points): The number of neighboring points used for covariance estimation. For LiDARs with sparse scan patterns (e.g., Velodyne VLP16), increase this value to 15 ~ 30 to avoid degeneration of covariance matrices.</p> </li> </ul> <p>Note</p> <p>To see if estimated covariances are fine, change <code>color_mode</code> in the standard viewer to <code>NORMAL</code>. If point colors are uniform on flat planes, covariances should be ok.</p>"},{"location":"parameters.html#gpu-based-lidar-imu-odometry-estimation-config_odometryjson","title":"GPU-based LiDAR-IMU Odometry Estimation (config_odometry.json)","text":"<ul> <li>voxel_resolution (default 0.25 m) : Base VGICP voxel resolution. Use a small value for indoor environments (e.g., 0.1 ~ 0.25 m).</li> <li>voxelmap_levels (default 2 levels): Multi resolution voxel levels. Increasing this parameter makes estimation robust to large displacement.</li> <li>max_num_keyframes (default 15 keyframes): Maximum number of keyframes. Increasing this parameter reduces odometry estimation drift.</li> <li>keyframe_update_strategy (default OVERLAP): \"OVERLAP\", \"DISPLACEMENT\", or \"ENTROPY\". <ul> <li>\"OVERLAP\" uses an overlap-metric-based keyframe management strategy that can adaptively deal with many environments (indoors and outdoors). Increasing keyframe_max_overlap makes keyframe insertion more frequent and robust to dynamic situations.</li> <li>\"DISPLACEMENT\" uses the conventional displacement-based keyframe management that is more intuitive to tune. Change keyframe_delta_(trans|rot) to tune the keyframe insertion frequency.</li> <li>\"ENTROPY\" uses an entropy-based keyframe management. This strategy is often difficult to tune and is not recommended.</li> </ul> </li> </ul>"},{"location":"parameters.html#cpu-based-lidar-imu-odometry-estimation-config_odometry_cpujson","title":"CPU-based LiDAR-IMU Odometry Estimation (config_odometry_cpu.json)","text":"<ul> <li> <p>registration_type (default GICP) : Either of \"GICP\" or \"VGICP\".</p> <ul> <li> <p>\"GICP\" uses iVox-based GICP scan matching that is accurate and robust in many cases.</p> <ul> <li>ivox_resolution (default 0.5 m) : Resolution of iVox voxels used for GICP scan matching. This parameter also controls the maximum corresponding distance and should be set to a large value in outdoor environments (e.g., 1.0 m).</li> </ul> </li> <li> <p>\"VGICP\" uses voxelized GICP scan matching that is faster but requires tuning vgicp_resolution parameter for good estimation in indoor environments.</p> <ul> <li>vgicp_resolution (default 0.5 m) : Resolution of VIGP voxels used for VGICP scan matching. Use a small value for indoor environments (e.g., 0.25 ~ 0.5 m) and a large value for outdoor environments (0.5 ~ 2.0 m).</li> </ul> </li> </ul> </li> </ul>"},{"location":"parameters.html#lidar-only-odometry-estimation-config_odometry_ctjson","title":"LiDAR-only Odometry Estimation (config_odometry_ct.json)","text":"<ul> <li>max_correspondence_distance (default 2.0 m) : Maximum corresponding distance for scan matching. </li> </ul>"},{"location":"parameters.html#global-optimization-config_sub_mappingjson-config_global_mappingjson","title":"Global Optimization (config_sub_mapping.json &amp; config_global_mapping.json)","text":""},{"location":"parameters.html#sub-mapping","title":"Sub mapping","text":"<ul> <li>enable_optimization (default true) : In environments where the odometry estimation is sufficiently robust and accurate, you can set this false to disable submap optimization and save the processing cost.</li> <li>keyframe-related params : These parameters control the keyframe creation in sub mapping. See GPU-based LiDAR-IMU odometry params for details.</li> </ul>"},{"location":"parameters.html#global-mapping","title":"Global mapping","text":"<ul> <li>min_implicit_loop_overlap (default 0.2) : Minimum overlap rate to create registration error factor.</li> </ul>"},{"location":"parameters.html#common-parameters-for-sub-and-global-mapping","title":"Common parameters for sub and global mapping","text":"<ul> <li>enable_imu (default true) : Must be false if the LiDAR-only odometry estimation is used.</li> <li>registration_error_factor_type (default \"VGICP_GPU\") : Registration error computation type. Must be either of \"VGICP\" or \"VGICP_GPU\".</li> <li>random_sampling_rate (default 1.0) : Random sampling rate for points used for registration error computation. With the GPU implementation, you can use a large random sampling rate (e.g., 1.0 = disabling random sampling) to perform full global registration error minimization.</li> <li>(submap|keyframe)_voxel_resolution (default 0.5 m) : Base voxel resolution. Set a small value (e.g., 0.15 ~ 0.25 m) for indoor environments.</li> <li>(submap|keyframe)_voxelmap_levels (default 2 levels) : Multi resolution voxel levels. Set this param to 2 or 3 for better convergence.</li> </ul>"},{"location":"quickstart.html","title":"Getting started","text":""},{"location":"quickstart.html#prerequisite","title":"Prerequisite","text":"<ol> <li>Install GLIM on your system following the installation section. Alternatively, you can also use prebuilt docker images.</li> <li> <p>Download test data.     ROS1: os1_128_01_downsampled.bag (515MB) or os1_128_01.bag (7.3GB)     ROS2: os1_128_01_downsampled.tar.gz (426MB) or os1_128_01.tar.gz (3.2GB)</p> <p>Alternative links (Google Drive): ROS1 (downsampled, raw)  ROS2 (downsampled, raw)</p> </li> <li> <p>Confirm the sensor configuration and ROS topic parameters are set as follows: <pre><code>glim/config/config.json\n  \"config_odometry\": \"config_odometry_gpu.json\",\n  \"config_sub_mapping\": \"config_sub_mapping_gpu.json\",\n  \"config_global_mapping\": \"config_global_mapping_gpu.json\",\nglim/config/config_sensors.json\n  \"T_lidar_imu\": [-0.006, 0.012, -0.008, 0, 0, 0, 1],\nglim/config/config_ros.json\n  \"imu_topic\": \"/os_cloud_node/imu\",\n  \"points_topic\": \"/os_cloud_node/points\",\n</code></pre></p> </li> </ol> <p>Tip</p> <p>If you want to try the CPU-based odometry estimation and global optimization, in <code>config.json</code>, set  <code>\"config_odometry\"</code> : <code>\"config_odometry_cpu.json\"</code>, <code>\"config_sub_mapping\"</code> : <code>\"config_sub_mapping_cpu.json\"</code>, <code>\"config_global_mapping\"</code> : <code>\"config_global_mapping_cpu.json\"</code>,</p> <p>Tip</p> <p>If you want to try the LiDAR-only odometry estimation without IMU data,  in <code>config.json</code>, set <code>\"config_odometry\"</code> : <code>\"config_odometry_ct.json\"</code>, and, in <code>config_sub_mapping_gpu.json</code> and <code>config_global_mapping_gpu.json</code>, set <code>\"enable_imu\"</code> : <code>false</code></p>"},{"location":"quickstart.html#executables","title":"Executables","text":"<p>GLIM provides two ROS executables: glim_rosnode and glim_rosbag.</p>"},{"location":"quickstart.html#glim_rosnode","title":"glim_rosnode","text":"<p>glim_rosnode launches GLIM as a standard ROS node that subscribes to points, imu, and image topics. </p> ROS1 command <pre><code># Start roscore\nroscore\n</code></pre> <pre><code># Enable use_sim_time and launch GLIM as a standard ROS node on another terminal\nrosparam set use_sim_time true\nrosrun glim_ros glim_rosnode\n</code></pre> <pre><code># Play rosbag on yet another terminal\nrosbag play --clock os1_128_01.bag\n</code></pre> <pre><code># Visualize on rviz (optional)\nrviz -d glim_ros1/rviz/glim_ros.rviz\n</code></pre> ROS2 command <pre><code>ros2 run glim_ros glim_rosnode\n</code></pre> <pre><code>ros2 bag play os1_128_01\n</code></pre> <pre><code>rviz2 -d glim_ros2/rviz/glim_ros.rviz\n</code></pre>"},{"location":"quickstart.html#glim_rosbag","title":"glim_rosbag","text":"<p>glim_rosbag launches a mapping instance that directly reads data from rosbag. It automatically adjusts the playback speed while avoiding data drop to perform mapping in a minimum time.</p> ROS1 command <pre><code>roscore\n</code></pre> <pre><code>rosparam set use_sim_time true\n</code></pre> <pre><code>rosrun glim_ros glim_rosbag os1_128_01.bag\n</code></pre> ROS2 command <pre><code>ros2 run glim_ros glim_rosbag os1_128_01\n</code></pre>"},{"location":"quickstart.html#configuration-files","title":"Configuration files","text":"<p>GLIM reads parameter settings from JSON files in a config root directory, which is set to <code>glim/config</code> by default. It first reads <code>config.json</code> that describes relative paths to submodule parameter files, and then reads parameters of submodules from specified configuration files. The config root directory can be changed by setting <code>config_path</code> ROS param when starting GLIM executables.</p> <p>Note</p> <p>If <code>config_path</code> starts with \"/\", the path is interpreted as an absolute path. Otherwise, <code>config_path</code> is interpreted as a path relative to <code>glim</code> directory. <code>realpath</code> command is useful to run GLIM with local configuration files out of the package directory: (e.g., <code>ros2 run glim_ros glim_rosnode --ros-args -p config_path:=$(realpath config)</code>)</p> <p>Note</p> <p>On ROS2, you need to run <code>colcon build</code> to apply changes of the configuration files in the package directory because ROS2 requires to place config files in the install directory. To avoid this, use <code>--symlink-install</code> option for <code>colcon build</code>.</p> <p>Info</p> <p>See Important parameters to understand parameters that should be fine-tuned.</p> <p>Example</p> ROS1 command <pre><code># Load parameters from \"glim/config/presets/gpu/config.json\"\nrosrun glim_ros glim_rosnode _config_path:=config/presets/gpu\n\n# Load parameters from \"/tmp/config/config.json\"\nrosrun glim_ros glim_rosnode _config_path:=/tmp/config\n\n# Load parameters from \"./config/config.json\"\nrosrun glim_ros glim_rosnode _config_path:=$(realpath ./config)\n</code></pre> ROS2 command <pre><code># Load parameters from \"glim/config/presets/gpu/config.json\"\nros2 run glim_ros glim_rosnode --ros-args -p config_path:=config/presets/gpu\n\n# Load parameters from \"/tmp/config/config.json\"\nros2 run glim_ros glim_rosnode --ros-args -p config_path:=/tmp/config\n\n# Load parameters from \"./config/config.json\"\nros2 run glim_ros glim_rosnode --ros-args -p config_path:=$(realpath ./config)\n</code></pre>"},{"location":"quickstart.html#mapping-result","title":"Mapping result","text":"<p>The mapping result data (dump data) is saved in <code>/tmp/dump</code> when closing glim_rosnode or glim_rosbag. The dump data can be visualized and edited using the offline viewer (<code>rosrun glim_ros offline_viewer</code>).</p> <p>Example dump data: dump_rosbag2_2024_04_16-14_17_01.tar.gz (trajectory errors injected for manual loop closure test)</p>"},{"location":"quickstart.html#offline-viewer-manual-map-editing-and-point-cloud-export","title":"Offline viewer (manual map editing and point cloud export)","text":"<pre><code># ROS1\nrosrun glim_ros offline_viewer\n\n# ROS2\nros2 run glim_ros offline_viewer\n</code></pre>"},{"location":"quickstart.html#open-map","title":"Open map","text":"<p><code>File</code> -&gt; <code>Open Map</code> -&gt; Select a dump directory.</p>"},{"location":"quickstart.html#create-explicit-loop-constraints","title":"Create explicit loop constraints","text":"<ul> <li><code>Right click a submap sphere</code> -&gt; <code>Loop begin</code> -&gt; <code>Right click another submap sphere</code> -&gt; <code>Loop end</code></li> <li>Roughly align red and green point clouds -&gt; Press <code>Align</code> to perform scan matching -&gt; Press <code>Create Factor</code> if the alignment result is fine.</li> </ul>"},{"location":"quickstart.html#create-plane-ba-constraints","title":"Create Plane-BA constraints","text":"<ul> <li><code>Right click a point on a flat surface</code> -&gt; <code>Bundle Adjustment (Plane)</code></li> <li>Adjust the sphere size so it covers sufficient points on the plane -&gt; <code>Create Factor</code></li> </ul>"},{"location":"quickstart.html#export-map-point-cloud-ply-format","title":"Export map point cloud (PLY format)","text":"<ul> <li><code>File</code> -&gt; <code>Save</code> -&gt; <code>Export Points</code></li> </ul>"},{"location":"quickstart.html#setup-your-own-sensor","title":"Setup your own sensor","text":"<p>See Sensor setup guide.</p>"}]}